{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - Projeto 2: Tinder#\n",
    "___\n",
    "\n",
    "### _Gabriela Caruso e Mayra Peter - 2C_ ###\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto: _Classificador Automático de Sentimento_ ##\n",
    "\n",
    "_Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing._\n",
    "\n",
    "_Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo._\n",
    "\n",
    "_Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma._\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ##\n",
    "\n",
    "O Tinder foi escolhido como produto a ser analizado devido a sua popularidade em redes sociais e a divergência de opiniões a seu respeito.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo ##\n",
    "\n",
    "Visando analisar o conteúdo de _tweets_ mencionando o Tinder e retornar se eles são ou não relevantes, foi criado um programa que percorre uma planilha de dados coletando informações e, por fim, retorna a  relevância dos dados a partir de suas respectivas probabilidades de ocorrência.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta e seleção de dados ##\n",
    "\n",
    "Foi criado um _dataframe_ contendo 500 _tweets_ mensionando o Tinder. Posteriormente foi classificado manualmente a relevância de cada um, sendo 0 (zero) não relevante e 1 (um) relevante.\n",
    "\n",
    "Para essa classificação consideramos opiniões favoráveis e desfavoráveis a respeito do produto e mensões que indicassem a eficiência do aplicativo quanto a proximidade dos usuários.\n",
    "\n",
    "Na célula abaixo está sendo importado o _dataframe_ inicial e separado em \"Treinamento\" (300 _tweets_), a partir do qual serão coletadas as probabilidades, e em \"Teste\" (200 _tweets_), no qual o programa analisará os dados coletados em \"Treinamento\" para calcular a relevância desses 200 _tweets_.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.ExcelFile('tweets_Tinder_201809041724.xlsx')\n",
    "data_treinamento = pd.read_excel(data, 'Treinamento')\n",
    "data_teste = pd.read_excel(data, 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos dados ##\n",
    "\n",
    "Para que o programa não analise partes desnecessárias dos _tweets_, os dados foram filtrados, retirando pontuações e simbolos não relevantes e arrumando espaçamentos incorretos (incluindo entre _emojis_).\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(',', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('.', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(':', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('/', ' ')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('#', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('@', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('?', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('\\n', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('rt', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('(', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(')', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('*', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('“', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('”', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('_', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('&', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(';', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('%', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(\"'\", '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('-', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('+', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(\"=\", '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('\"', '')\n",
    "\n",
    "data_teste.Teste = data_teste.Teste.str.replace(',', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('.', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(':', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('/', ' ')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('#', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('@', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('?', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('rt', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('\\n', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('(', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(')', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('*', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('“', ' ')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('”', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('_', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('&', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(';', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('%', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(\"'\", '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('-', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('+', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('=', ' ')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('\"', '')\n",
    "\n",
    "lista_espaco = []\n",
    "for each in data_treinamento['Treinamento']:\n",
    "    e = ''\n",
    "    for word in each:\n",
    "        if word in UNICODE_EMOJI:\n",
    "            e += \" \" + word + ' '\n",
    "        else:\n",
    "            e += word\n",
    "    lista_espaco.append(e)\n",
    "    \n",
    "data_treinamento['Treinamento'] = lista_espaco\n",
    "\n",
    "lista_espaco2 = []\n",
    "for each in data_teste['Teste']:\n",
    "    e = ''\n",
    "    for word in each:\n",
    "        if word in UNICODE_EMOJI:\n",
    "            e += \" \" + word + ' '\n",
    "        else:\n",
    "            e += word\n",
    "    lista_espaco2.append(e)\n",
    "    \n",
    "data_teste['Teste'] = lista_espaco2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados ##\n",
    "\n",
    "Para facilitar o cálculo das probabilidades, a partir da planilha de treinamento, foram criadas duas novas planilhas, uma contendo os _tweets_ relevantes e outra os irrelevantes.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treinamento_relevantes = data_treinamento[(data_treinamento['Relevância'] == 1)]\n",
    "data_treinamento_irrelevantes = data_treinamento[(data_treinamento['Relevância'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terceira vez que dou match com a mesma pessoa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eduaaarda eu n sei pq ainda insisto em instal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tal qual o ubero tinder tinha que ter uma área...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>karlasnotsorry gente eu criei um tinder da no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>karlasnotsorry gente eu criei um tinder da no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Treinamento  Relevância\n",
       "2   terceira vez que dou match com a mesma pessoa ...           1\n",
       "5    eduaaarda eu n sei pq ainda insisto em instal...           1\n",
       "6   tal qual o ubero tinder tinha que ter uma área...           1\n",
       "12   karlasnotsorry gente eu criei um tinder da no...           1\n",
       "13   karlasnotsorry gente eu criei um tinder da no...           1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_treinamento_relevantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o cara do tinder ficou brabo cmg pq eu disse q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fica a questão tinder https  tco iq7iyzucdd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta pra 2018 deletar o tinder ainda esse ano ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>para todos os matches do tinder que eu não man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to muito confuso hoje to tipo gente que namora...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  o cara do tinder ficou brabo cmg pq eu disse q...           0\n",
       "1        fica a questão tinder https  tco iq7iyzucdd           0\n",
       "3  meta pra 2018 deletar o tinder ainda esse ano ...           0\n",
       "4  para todos os matches do tinder que eu não man...           0\n",
       "7  to muito confuso hoje to tipo gente que namora...           0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_treinamento_irrelevantes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando listas ##\n",
    "\n",
    "Para separar as palavras, foram criadas três listas. A primeira contendo todas as palavras,  uma segunda contendo as palavras relevantes e outra com as irrelevantes.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "relevante = []\n",
    "irrelevante = []\n",
    "    \n",
    "for each in data_treinamento_relevantes['Treinamento']:\n",
    "    relevante.append(each.split())\n",
    "    \n",
    "for each in data_treinamento_irrelevantes['Treinamento']:\n",
    "    irrelevante.append(each.split())\n",
    "\n",
    "for each in data_treinamento['Treinamento']:\n",
    "    tweets.append(each.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contando palavras ##\n",
    "\n",
    "Para cada uma das listas foi criada uma variável que conta o numero de palavras nela presente.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_irrelevantes = data_treinamento.Relevância[data_treinamento.Relevância == 0].count()\n",
    "n_relevantes = data_treinamento.Relevância[data_treinamento.Relevância == 1].count()\n",
    "total = n_relevantes + n_irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcentagem: palavras relevantes ##\n",
    "\n",
    "Foi calculada a porcentagem das palavras relevantes e das irrelevantes.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_irrelevante = n_irrelevantes/ total\n",
    "prob_relevante = n_relevantes/ total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicionário ##\n",
    "\n",
    "Foram criados três dicionários e três novas listas. As novas listas servem para usar apenas as palavras das antigas, que estavam subdivididas em listas. Os dicionários criados (um para as palavras relevantes, um para as irrelevantes, e outro para todas as palavras) contém as palavras e um valor atrubuído à cada uma delas, referente ao número de aparições de cada palavra em cada categoria (relevante, irrelevante ou todas).\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_rel = {}\n",
    "dicionario_irrel = {}\n",
    "dicionario_todos = {}\n",
    "\n",
    "lista_nova_rel = []\n",
    "lista_nova_irrel = []\n",
    "todos = []\n",
    "\n",
    "for lista in relevante:\n",
    "    for word in lista:\n",
    "        lista_nova_rel.append(word)\n",
    "        dicionario_rel[word] = lista_nova_rel.count(word)\n",
    "\n",
    "for lista in irrelevante:\n",
    "    for word in lista:\n",
    "        lista_nova_irrel.append(word)\n",
    "        dicionario_irrel[word] = lista_nova_irrel.count(word)\n",
    "\n",
    "for lista in tweets:\n",
    "    for word in lista:\n",
    "        todos.append(word)\n",
    "        dicionario_todos[word] = todos.count(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrando ##\n",
    "\n",
    "Para o teorema de Bayes, é necessário saber quantas palavras aparecem no total, sem repetições. Para isso foi criada a lista abaixo.\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(set(todos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidade##\n",
    "\n",
    "Na célula abaixo, são criados dois dicionários. Em um deles, foi utilizado o teorema de Bayes (já usando o Laplace Smoothing) para calcular a probabilidade de uma palavra ser relevante, e no outro, o mesmo teorema foi utilizado para calcular a probabilidade de uma palavra ser irrelevante. Ambos dicionários contém palavras relacionadas a valores, que representam as devidas probabilidades.\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = {}\n",
    "p_ir = {}\n",
    "\n",
    "for word in lista_nova_rel:\n",
    "    p_r[word] = (dicionario_rel[word] + 1)/ (len(a) + len(lista_nova_rel))\n",
    "\n",
    "for word in lista_nova_irrel:\n",
    "    p_ir[word] = (dicionario_irrel[word] + 1)/ (len(a) + len(lista_nova_irrel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação ##\n",
    "\n",
    "Após a probabilidade de cada palavra ser calculada, já é possível usar o teorema de Bayes para analisar a relevância dos _tweets_ da planilha de teste.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancia = []\n",
    "\n",
    "for frase in data_teste['Teste']:\n",
    "    \n",
    "#para cada frase, reiniciando a probabilidade de ser relevante ou não.\n",
    "\n",
    "    p_fraser = 1\n",
    "    p_fraseir = 1\n",
    "    palavra_frase2 = []\n",
    "    palavra_frase2.append(frase.split())\n",
    "    for lista in palavra_frase2:\n",
    "        for word in lista:\n",
    "            palavra_frase = []\n",
    "            palavra_frase.append(word)\n",
    "            \n",
    "#criando uma lista que contém uma palavra a cada loop.\n",
    "\n",
    "            for palavra in palavra_frase:\n",
    "        \n",
    "#zerando a probabilidade da palavra ser relevante ou não.\n",
    "\n",
    "                p_pal_ir = 0\n",
    "                p_pal_r = 0\n",
    "        \n",
    "#determinando que, se a palavra estiver no dicionário de probabilidade das palavras relevantes, a probabilidade da frase ser relevante é multiplicada por esse valor. \n",
    "\n",
    "                if palavra in p_r:\n",
    "                    p_pal_r = p_r[palavra]\n",
    "                    p_fraser *= p_pal_r\n",
    "                \n",
    "#determinando que, se a palavra estiver no dicionário de probabilidade das palavras irrelevantes, a probabilidade da frase ser irrelevante é multiplicada por esse valor.\n",
    "                \n",
    "                elif palavra in p_ir:\n",
    "                    p_pal_ir = p_ir[palavra]\n",
    "                    p_fraseir *= p_pal_ir\n",
    "                    \n",
    "#determinando que, se a palavra não se encontrar em nenhum dos dicionários, a probabilidade dela ser relevante ou irrelevante é calculada pelo teorema de Bayes usando o Laplace Smoothing, e, a probabilidade da frase ser relevante ou irrelevante é multiplacada por esses valores, respectivamente.\n",
    "\n",
    "                else:\n",
    "                    p_pal_ir = 1/(len(lista_nova_irrel) + len(a))\n",
    "                    p_pal_r = 1/(len(lista_nova_rel) + len(a))\n",
    "                    p_fraser *= p_pal_r\n",
    "                    p_fraseir *= p_pal_ir\n",
    "                    \n",
    "#comparando a probabilidade da frase ser relevante com a probabilidade da mesma ser irrelevante. \n",
    "                    \n",
    "    if p_fraser > p_fraseir:\n",
    "        \n",
    "#se a probabilidade de ser relevante for maior, é adicionado para uma lista o valor 1.\n",
    "        \n",
    "        relevancia.append(1)\n",
    "    else:\n",
    "        \n",
    "#caso contrário, é adicionado para a mesma lista o valor 0.\n",
    "        \n",
    "        relevancia.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserção de coluna ##\n",
    "\n",
    "Com os valores de relevância já calculados, é criada uma coluna no _dataframe_ de teste e inseridos tais valores.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_teste['Chute'] = relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo da acertos e erros do programa ##\n",
    "\n",
    "Analisando a coerência entre a coluna classificada manualmente e a classificada pelo programa, pode-se calcular o número de positivos verdadeiros, negativos verdadeiros, positivos falsos e negativos falsos.\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = 0\n",
    "vn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(len(data_teste)):\n",
    "    if data_teste['Chute'][i] == 1 and data_teste['Relevância'][i] == 1:\n",
    "        vp += 1\n",
    "    elif data_teste['Chute'][i] == 0 and data_teste['Relevância'][i] == 1:\n",
    "        fn += 1\n",
    "    elif data_teste['Chute'][i] == 0 and data_teste['Relevância'][i] == 0:\n",
    "        vn += 1\n",
    "    else:\n",
    "        fp += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo da porcentagem de acertos e erros ##\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de positivos verdadeiros é: 4.5 %\n",
      "A porcentagem de negativos verdadeiros é: 55.5 %\n",
      "A porcentagem de positivos falsos é: 11.0 %\n",
      "A porcentagem de negativos falsos é: 29.0 %\n"
     ]
    }
   ],
   "source": [
    "print('A porcentagem de positivos verdadeiros é:', vp/2,'%')\n",
    "print('A porcentagem de negativos verdadeiros é:', vn/2,'%')\n",
    "print('A porcentagem de positivos falsos é:', fp/2,'%')\n",
    "print('A porcentagem de negativos falsos é:', fn/2,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão: ##\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cálculo de porcentagem de acertos e erros indica que 60% do das previsões estão corretas e 40% erradas. Dentre as erradas, 29% foram negativos falsos, o que indica que essas informações eram relevantes e foram perdidas e 11% foram positivos falsos, o que indica que essas informações não eram relevantes e foram levadas em consideração.\n",
    "\n",
    "A partir desses resultados é possível concluir que o programa não foi capaz de classificar veridicamente os dados selecionados.\n",
    "\n",
    "Primeiramente, a quantidade de dados que foram selecionados para a análise é insuficiente para gerar um resultado aproximado da realidade. Outra falha do programa é a leitura de palavras como independentes dentro de uma frase, o que leva a incapacidade de interpretação sintática, como em casos de dupla negação e sarcásmo, resultando em erros de classifição. Além disso, a alta frequência de _retweets_ impede uma analise mais apurada. Isso ocorre pois, devido a repetição das frases, a probabilidade de ocorrência das palavras que as compõe aumenta, e a quantidade de dados a serem analisados fica ainda mais restrita.\n",
    "\n",
    "Apesar desses defeitos, o projeto mantém uma base eficiente que, com alguns ajustes, como o aumento da quantidade de dados selecionados, a filtração de _retweets_ e a capacidade de interpretação sintática, pode se tornar útil para o Tinder, por diminuir a quantidade de _tweets_ a serem analisados sobre o mesmo, reduzindo tempo e custo a ser nisso investido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
