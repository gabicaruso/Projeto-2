{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o cara do tinder ficou brabo cmg pq eu disse q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fica a questão tinder https  tco iq7iyzucdd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terceira vez que dou match com a mesma pessoa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta pra 2018 deletar o tinder ainda esse ano ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>para todos os matches do tinder que eu não man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  o cara do tinder ficou brabo cmg pq eu disse q...           0\n",
       "1        fica a questão tinder https  tco iq7iyzucdd           0\n",
       "2  terceira vez que dou match com a mesma pessoa ...           1\n",
       "3  meta pra 2018 deletar o tinder ainda esse ano ...           0\n",
       "4  para todos os matches do tinder que eu não man...           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reset -f\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "\n",
    "data = pd.ExcelFile('tweets_Tinder_201809041724.xlsx')\n",
    "data_treinamento = pd.read_excel(data, 'Treinamento')\n",
    "data_teste = pd.read_excel(data, 'Teste')\n",
    "\n",
    "\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(',', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('.', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(':', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('/', ' ')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('#', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('@', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('?', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('?', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('\\n', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('rt', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('(', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(')', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('*', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('“', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('”', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('_', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('&', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(';', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('%', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(\"'\", '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('-', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('+', '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace(\"=\", '')\n",
    "data_treinamento.Treinamento = data_treinamento.Treinamento.str.replace('\"', '')\n",
    "\n",
    "data_teste.Teste = data_teste.Teste.str.replace(',', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('.', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(':', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('/', ' ')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('#', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('@', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('?', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('rt', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('\\n', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('(', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(')', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('*', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('“', ' ')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('”', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('_', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('&', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(';', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('%', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace(\"'\", '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('-', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('+', '')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('=', ' ')\n",
    "data_teste.Teste = data_teste.Teste.str.replace('\"', '')\n",
    "\n",
    "\n",
    "lista_espaco = []\n",
    "for each in data_treinamento['Treinamento']:\n",
    "    e = ''\n",
    "    for word in each:\n",
    "        if word in UNICODE_EMOJI:\n",
    "            e += \" \" + word + ' '\n",
    "        else:\n",
    "            e += word\n",
    "    lista_espaco.append(e)\n",
    "    \n",
    "data_treinamento['Treinamento'] = lista_espaco\n",
    "\n",
    "data_treinamento_relevantes = data_treinamento[(data_treinamento['Relevância'] == 1)]\n",
    "data_treinamento_irrelevantes = data_treinamento[(data_treinamento['Relevância'] == 0)]\n",
    "\n",
    "data_teste_relevantes = data_teste[(data_teste['Relevância'] == 1)]\n",
    "data_teste_irrelevantes = data_teste[(data_teste['Relevância'] == 0)]\n",
    "\n",
    "\n",
    "\n",
    "data_treinamento.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "relevante = []\n",
    "irrelevante = []\n",
    "\n",
    "for each in data_treinamento['Treinamento']:\n",
    "    each = each.lower()\n",
    "    \n",
    "for each in data_treinamento_relevantes['Treinamento']:\n",
    "    relevante.append(each.split())\n",
    "    \n",
    "for each in data_treinamento_irrelevantes['Treinamento']:\n",
    "    irrelevante.append(each.split())\n",
    "\n",
    "for each in data_treinamento['Treinamento']:\n",
    "    tweets.append(each.split())\n",
    "\n",
    "\n",
    "n_irrelevantes = data_treinamento.Relevância[data_treinamento.Relevância == 0].count()\n",
    "n_relevantes = data_treinamento.Relevância[data_treinamento.Relevância == 1].count()\n",
    "\n",
    "total = n_relevantes + n_irrelevantes\n",
    "\n",
    "prob_irrelevante = n_irrelevantes/ total\n",
    "prob_relevante = n_relevantes/ total\n",
    "\n",
    "dicionario_rel = {}\n",
    "dicionario_irrel = {}\n",
    "dicionario_todos = {}\n",
    "\n",
    "lista_nova_rel = []\n",
    "lista_nova_irrel = []\n",
    "todos = []\n",
    "\n",
    "for lista in relevante:\n",
    "    for word in lista:\n",
    "        lista_nova_rel.append(word)\n",
    "        dicionario_rel[word] = lista_nova_rel.count(word)\n",
    "\n",
    "for lista in irrelevante:\n",
    "    for word in lista:\n",
    "        lista_nova_irrel.append(word)\n",
    "        dicionario_irrel[word] = lista_nova_irrel.count(word)\n",
    "\n",
    "for lista in tweets:\n",
    "    for word in lista:\n",
    "        todos.append(word)\n",
    "        dicionario_todos[word] = todos.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5142\n",
      "1573\n",
      "3569\n"
     ]
    }
   ],
   "source": [
    "print(len(todos))\n",
    "print(len(lista_nova_rel))\n",
    "print(len(lista_nova_irrel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470\n",
      "5142\n"
     ]
    }
   ],
   "source": [
    "a= list(set(todos))\n",
    "print(len(a))\n",
    "print(len(todos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = len(lista_nova_rel)/len(todos)\n",
    "ir = len(lista_nova_irrel)/len(todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = {}\n",
    "p_ir = {}\n",
    "\n",
    "for word in lista_nova_rel:\n",
    "    p_r[word] = (dicionario_rel[word] + 1)/ (len(a) + len(lista_nova_rel))\n",
    "\n",
    "for word in lista_nova_irrel:\n",
    "    p_ir[word] = (dicionario_irrel[word] + 1)/ (len(a) + len(lista_nova_irrel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.624465547304819\n"
     ]
    }
   ],
   "source": [
    "d = sum(p_r.values())\n",
    "b = sum(p_ir.values())\n",
    "\n",
    "print(b + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavra|relevante = n°emrelevantes + 1/ palavrasrelevantes + palavrastotaisumavez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "relevancia = []\n",
    "listnew = []\n",
    "for frase in data_teste['Teste']:\n",
    "    palavra_frase2 = []\n",
    "    palavra_frase2.append(frase.split())\n",
    "    p_fraseir = 1\n",
    "    p_pal_ir = 0\n",
    "    p_fraser = 1\n",
    "    p_pal_r = 0\n",
    "    for lista in palavra_frase2:\n",
    "        for word in lista:\n",
    "            palavra_frase = []\n",
    "            palavra_frase.append(word)                          \n",
    "            for palavra in palavra_frase:\n",
    "                p_fraseir = 1\n",
    "                p_pal_ir = 0\n",
    "                p_fraser = 1\n",
    "                p_pal_r = 0\n",
    "                #print(palavra)\n",
    "                if palavra in p_r:\n",
    "                    p_pal_r = p_r[palavra]\n",
    "                    p_fraser *= p_pal_r\n",
    "                elif palavra in p_ir:\n",
    "                    p_pal_ir = p_ir[palavra]\n",
    "                    p_fraseir *= p_pal_ir\n",
    "                else:\n",
    "                    p_pal_ir = 1/(len(lista_nova_irrel) + len(a))\n",
    "                    p_pal_r = 1/(len(lista_nova_rel) + len(a))\n",
    "                    p_fraser *= p_pal_r\n",
    "                    p_fraseir *= p_pal_ir\n",
    "    if p_fraser > p_fraseir:\n",
    "        relevancia.append(1)\n",
    "    else:\n",
    "        relevancia.append(0)\n",
    "\n",
    "\n",
    "    \n",
    "data_teste['Chute'] = relevancia\n",
    "\n",
    "vp = 0\n",
    "vn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(len(data_teste)):\n",
    "    if data_teste['Chute'][i] == 1 and data_teste['Relevância'][i] == 1:\n",
    "        vp += 1\n",
    "    elif data_teste['Chute'][i] == 0 and data_teste['Relevância'][i] == 1:\n",
    "        fn += 1\n",
    "    elif data_teste['Chute'][i] == 0 and data_teste['Relevância'][i] == 0:\n",
    "        vn += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de positivos verdadeiros é: 19.5 %\n",
      "A porcentagem de negativos verdadeiros é: 23.0 %\n",
      "A porcentagem de positivos falsos é: 43.5 %\n",
      "A porcentagem de negativos falsos é: 14.0 %\n"
     ]
    }
   ],
   "source": [
    "print('A porcentagem de positivos verdadeiros é:', vp/2,'%')\n",
    "print('A porcentagem de negativos verdadeiros é:', vn/2,'%')\n",
    "print('A porcentagem de positivos falsos é:', fp/2,'%')\n",
    "print('A porcentagem de negativos falsos é:', fn/2,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
